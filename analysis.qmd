---
title: "Applied Retail Forecasting"
format:
  html:
    toc: true
    toc-depth: 3
    number-sections: true
    code-fold: true
execute:
  echo: false
---

# Overview

This project applies classical time series forecasting techniques to Australian retail turnover data, with a focus on furniture and household goods retailing in the Northern Territory of Australia. Using monthly data published by the Australian Bureau of Statistics, the analysis aims to understand the underlying structure of the series and assess how different forecasting approaches perform in practice.

The workflow follows a standard applied forecasting process. The data are first explored to identify trends, seasonality, and structural changes, including the impact of major economic events such as COVID-19. Variance-stabilising transformations and decomposition techniques are then used to better understand the series before fitting and evaluating models.

Two model families are considered: Exponential Smoothing State Space (ETS) models and Seasonal ARIMA models. Model selection is guided by a combination of information criteria, residual diagnostics, and out-of-sample performance using a 24-month test set. Forecast accuracy is further assessed by comparing model predictions to subsequently released ABS data.

The goal of this project is not only to produce forecasts, but to demonstrate a transparent and defensible forecasting workflow, highlighting the trade-offs between model interpretability, stability, and responsiveness when applied to real-world economic data.

# Data

This analysis uses monthly retail turnover data from the Australian Bureau of Statistics (ABS), Retail Trade, Table 11.

The series represents turnover for furniture, floor coverings, houseware and textile goods retailing in the Northern Territory of Australia, measured in millions of Australian dollars. The data span April 1988 to December 2022 and are observed at a monthly frequency. A small sample of the dataset is shown below.

```{r}
#| label: load-libraries
#| message: false

# Loading libraries

library(tidyverse)
library(fpp3)
library(janitor)
library(lubridate)
library(patchwork)
library(readabs)
library(yardstick)
library(gt)

```

```{r}
#| label: get-data
#| message: false
#| eval: false

# Get data from ABS
retail <- read_abs(cat_no = "8501.0", tables = 11) |>
  filter(series_id == "A3349526J") |>
  transmute(
    State = "Northern Territory",
    Industry = "Furniture, floor coverings, houseware and textile goods retailing",
    `Series ID` = series_id,
    Month = yearmonth(date),
    Turnover = value
  ) |>
  as_tsibble(index = Month)

# For simplicity purposes, the dataset will be saved to local
# write_csv(retail, "data/retail.csv")
# write_rds(retail, "data/retail.rds")

```


```{r}
#| label: load-and-clean-data

# For simplicity purposes, the dataset will be loaded from local
retail <- read_rds("data/retail.rds")

# Clean and prepare for analysis
retail_clean <- retail |> 
  clean_names() |> 
  drop_na() |>
  filter(month <= yearmonth("2022 Dec"))

```


```{r}
#| label: data-split

# Splitting the data into train and test sets

# Training set: up to and including 2020
retail_train <- retail_clean |> 
  slice_head(n = nrow(retail_clean) - 24)

# Test set: from 2020 onwards
retail_test <- retail_clean |> 
  slice_tail(n = 24)

```

```{r}
#| label: raw-data-snippet

gt(head(retail_clean))

```


# Exploratory Data Analaysis (EDA)

Exploratory analysis is used to understand the overall structure of the retail turnover series before any modeling is performed. This includes examining long-term trends, seasonal patterns, and changes in variability over time, as well as identifying potential structural breaks linked to broader economic conditions.

A set of time series visualizations are used to assess these features. These plots help determine whether the series exhibits trend and seasonality, whether variance appears constant over time, and whether there are periods of unusually high or low volatility. Particular attention is given to changes around major events such as the mining boom period and the COVID-19 pandemic, both of which are expected to have influenced retail behaviour in the Northern Territory.

The insights from this exploratory stage inform later decisions around transformation, decomposition, and model selection.


## Trend, seasonality, and structural features

```{r}
#| label: fig-plot1
#| message: false
#| error: false
#| warning: false

# Plotting the dataset to see original structure
autoplot(retail_clean) + 
  theme_bw() +
  labs(title = "Autoplot of the Retail Dataset",
       x = "Month (1M)",
       y = "Turnover ($ Millions)")

```

```{r}
#| label: fig-plot2
#| message: false
#| error: false
#| warning: false

# Plotting a season plot to view seasonality by year
retail_clean |> 
  gg_season(turnover) +
  theme_bw() +
  labs(title = "Season Plot of the Retail Dataset",
       x = "Month (1M)",
       y = "Turnover ($ Millions)")

```

```{r}
#| label: fig-plot3
#| message: false
#| error: false
#| warning: false

# Plotting a subseries plot to see trend and patterns over each month 
# across all years
retail_clean |> gg_subseries(turnover) +
  theme_bw() +
  labs(title = "Subseries Plot of the Retail Dataset",
       x = "Month (1M)",
       y = "Turnover ($ Millions)") +
  theme(axis.text.x = element_text(angle = 60,
                                   hjust = 1))

```


The dataset captures monthly retail turnover for furniture, floor coverings, houseware and textile goods retailing in the Northern Territory, spanning April 1988 to December 2022.

The time series plot in @fig-plot1 shows a clear upward long-term trend, indicating sustained growth in retail turnover over the sample period. Seasonal behaviour is also evident, with fluctuations that increase in magnitude as the level of the series rises, suggesting multiplicative seasonality. A pronounced increase in turnover is observed between approximately 2007 and 2009, which likely reflects the effects of the Northern Territory mining boom during that period. Following this, turnover declines sharply post-2010, potentially linked to the global financial crisis and the subsequent slowdown in mining-related economic activity.

In the years leading up to 2020, turnover appears relatively subdued before rising again during and after the COVID-19 period. While many industries experienced contraction during this time, the increase observed here may reflect shifts in household behaviour, with greater emphasis on home-related spending as lifestyles adjusted. Given the broad scope of this retail category, multiple overlapping factors are likely influencing the observed dynamics.

The seasonal plot in @fig-plot2 highlights strong and consistent seasonal patterns across years. Turnover tends to peak in June and December, while lower values are commonly observed around February and April. The regular repetition of these patterns supports the presence of true seasonality rather than irregular cyclical effects. Although the exact drivers are not directly observed in the data, these patterns may be associated with factors such as end-of-financial-year spending, holiday periods, and seasonal changes in consumer behaviour.

The subseries plot in @fig-plot3 further reinforces these findings by displaying monthly behaviour across the full time span. Each month exhibits a distinct seasonal profile, while also reflecting the broader upward movement in turnover over time. June and December consistently record higher average turnover, whereas February and April remain comparatively weaker months. The horizontal reference lines representing monthly means make these differences particularly clear.

One notable feature in the subseries plot is an unusually high turnover value observed in July around 2007. This may represent a genuine economic anomaly linked to exceptional conditions during that period, although the possibility of a data irregularity cannot be ruled out. Overall, the exploratory analysis confirms the presence of trend, seasonality, and changing variance, all of which are important considerations for subsequent transformation and model selection.

## Data transformation and decomposition

This section focuses on preparing the series for modelling by addressing changing variance and separating the underlying components of the time series. These steps help ensure that subsequent models are applied to data that are more stable and interpretable.

### Variance stabilisation using the Box–Cox transformation

```{r}

# Extracting Guerrero lambda value for Box-Cox Transformation
lambda_retail <- retail_train |> 
  features(turnover, features = guerrero) |> 
  pull(lambda_guerrero)

```

```{r}

# Transforming the dataset with lambda 
bct_plot1 <- retail_train |> 
  autoplot(box_cox(turnover, lambda_retail)) +
  theme_bw() +
  labs(title = "Lambda Transformed Retail Dataset",
       x = "Month (1M)",
       y = "Lambda Transformed Turnover ($ Millions)") +
  theme(plot.title = element_text(size = 12))

```

```{r}

# Transforming the dataset with log 
bct_plot2 <- retail_train |> 
  autoplot(box_cox(turnover, 0)) +
  theme_bw() +
  labs(title = "Log Transformed Retail Datase",
       x = "Month (1M)",
       y = "Log Transformed Turnover ($ Millions)")  +
  theme(plot.title = element_text(size = 12))

```

```{r}
#| label: fig-plot4
#| message: false
#| error: false
#| warning: false

# Plotting both of the figures side by side
bct_plot1 + bct_plot2

```

To stabilize the variance of the series and address heteroskedasticity, a Box–Cox transformation is applied to the retail turnover data. The transformation parameter 
λ is selected using the Guerrero method, which chooses the value that minimizes variability across seasonal subseries. Applying this procedure yields an estimated λ value of 0.242.

Figure @fig-plot4 compares the Box–Cox transformation using the Guerrero-estimated value with a log transformation, corresponding to λ = 0. Both transformations reduce variance instability relative to the original series; however, the log-transformed series exhibits slightly tighter peaks and troughs, indicating more consistent variance across seasonal periods. The estimated value being close to zero suggests that a log transformation is sufficient in practice.

Overall, comparison with the original series in @fig-plot1 indicates that the transformation is effective in achieving approximate variance stability, making the data more suitable for subsequent decomposition and time series modelling.

### Seasonal-trend decomposition using STL

```{r}
#| label: fig-plot5
#| message: false
#| error: false
#| warning: false

# Creating a new variable with the box_cox transformed data
retail_train <- retail_train |> 
  mutate(bc_turnover = box_cox(turnover, 0))

# Performing STL Decomposition
retail_train |> 
  model(stl = STL(bc_turnover ~ season(window = 13) +
                    trend(window = 25),
                    robust = TRUE)) |> 
  components() |> 
  autoplot() +
  theme_bw() +
  labs(title = "STL Decomposition | season=13 & trend=25",
       x = "Month (1M)")

```

Following variance stabilization, the transformed series is decomposed using STL to separate the trend, seasonal, and remainder components. This helps assess whether seasonality is stable over time and whether any meaningful structure remains unexplained.

Because the series spans multiple decades, STL parameters are adjusted rather than relying on defaults. The seasonal window is set to 13 to allow the seasonal component to vary smoothly while still reflecting an annual cycle, which is appropriate for monthly retail data where recurring patterns such as end-of-financial-year and holiday periods are expected. The trend window is set to 25 to capture medium-term movements (roughly two years), allowing the trend component to reflect gradual shifts associated with changing economic conditions in the Northern Territory.

Given the presence of irregular spikes and sharp movements, particularly between 2007 and 2022, `robust = TRUE` is used to reduce the influence of extreme observations on the estimated components. With these settings, the decomposition in @fig-plot5 shows a well-defined long-term trend, a stable seasonal pattern, and a remainder that appears largely noise-like, suggesting that the major structure of the series has been captured.

Overall, the STL decomposition confirms that this turnover series is characterized by a persistent long-run trend and consistent seasonal variation year to year, supporting the use of seasonal forecasting models in later sections.

### Stationarity and differencing

```{r}
#| label: tbl-table1

## KPSS Test Before transformation

retail_train |> 
  select(-c(state, industry, turnover)) |> 
  features(bc_turnover, unitroot_kpss)

```

```{r}
#| label: tbl-table2

## Number of seasonal differences recommended

retail_train |> 
  select(-c(state, industry, turnover)) |> 
  features(bc_turnover, unitroot_nsdiffs)

```


```{r}
#| label: tbl-table3

## Number of regular differences recommended

retail_train |> 
  select(-c(state, industry, turnover)) |> 
  features(bc_turnover, unitroot_ndiffs)

```


```{r}
#| label: tbl-table4

## KPSS Test after transformation 

retail_train <- retail_train |>
  mutate(transformed = box_cox(turnover, 0) |>
    difference(12) |>
    difference(1))

retail_train |>
  select(-c(state, industry)) |>
  features(transformed, unitroot_kpss)

```

```{r}
#| label: fig-plot6
#| message: false
#| error: false
#| warning: false

# Plotting the data after seasonal differencing on 
# the box cox transformed dataset

retail_train |> 
  autoplot(bc_turnover |> 
             difference(12)) +
  theme_bw() +
  labs(title = "Seasonally Differenced Retail Dataset",
       x = "Month (1M)",
       y = "Turnover ($ Millions)")

```


```{r}
#| label: fig-plot7
#| message: false
#| error: false
#| warning: false

# Plotting the data after first order differencing on
# the box cox transformed dataset

retail_train |> 
  autoplot(bc_turnover |> 
             difference(12) |> 
             difference(1)) +
  theme_bw() +
  labs(title = "Seasonally and First Differenced Retail Dataset",
       x = "Month (1M)",
       y = "Turnover ($ Millions)")


```

Before fitting ARIMA models, the series must be made stationary by removing any remaining trend and seasonal structure. Visual inspection of the original series in @fig-plot1 confirms the presence of both trend and seasonality, while the Box–Cox transformation applied earlier successfully stabilizes variance, as seen in @fig-plot4.

To formally assess stationarity and guide differencing decisions, a set of unit root tests are applied to the transformed series. The KPSS test results in @tbl-table1 return a p-value of 0.01, providing evidence against stationarity in the undifferenced series. Automated differencing diagnostics suggest applying one seasonal difference (@tbl-table2) and one regular difference (@tbl-table3).

After applying both a seasonal difference of order 12 and a first-order difference, the KPSS test is repeated on the fully differenced series. The resulting p-value of 0.1 in @tbl-table4 indicates that there is no strong evidence against stationarity, suggesting that the differencing strategy has been effective.

This progression is also reflected visually. The seasonally differenced series shown in @fig-plot6 no longer exhibits clear seasonal patterns, but still displays some residual structure. Applying an additional first-order difference yields the series in @fig-plot7, which fluctuates around a constant mean with no obvious trend or seasonality, consistent with a stationary process.

Overall, these results indicate that one seasonal difference and one regular difference are sufficient to achieve stationarity, providing an appropriate foundation for ARIMA model identification in the next section.

# Model Identification and Selection

## Candidate model specification

### Exponential smoothing (ETS) models

Based on the exploratory analysis, the series exhibits a clear trend, strong seasonality, increasing variance, and occasional sharp movements. These characteristics motivate the use of exponential smoothing models that can accommodate trend damping and multiplicative effects.

A set of candidate ETS models is considered. All models use a damped additive trend to reflect the expectation that long-run growth may flatten over time, particularly given the observed fluctuations in the series. The shortlisted models include:

1) an additive Holt–Winters specification, 
2) a hybrid model with multiplicative errors and additive seasonality, 
3) a fully multiplicative specification, 
4) and an automatically selected ETS model.

These candidates allow comparison between different assumptions about how variance and seasonal effects scale with the level of the series.

### ARIMA model identification

```{r}
#| label: fig-plot8
#| message: false
#| error: false
#| warning: false

# Plotting the ACF and PACF Plots for ARIMA Model Identification
retail_train |>
  gg_tsdisplay(transformed, plot_type = "partial", lag = 36) +
  labs(title = "ACF and PACF Plots For ARIMA Model Identification")

```

ARIMA model identification is guided by the autocorrelation and partial autocorrelation functions of the transformed and differenced series, shown in @fig-plot8. One regular difference and one seasonal difference are retained, consistent with the stationarity analysis in the previous section, resulting in a baseline structure of (0,1,0)(0,1,0)[12].

Inspection of the ACF suggests the presence of a non-seasonal moving average component at lag 1, while the PACF indicates a potential non-seasonal autoregressive component at lag 2. At the seasonal level, a significant spike at lag 12 in the ACF suggests a seasonal MA(1) term, while spikes at lags 12 and 24 in the PACF indicate a possible seasonal AR(2) structure.

Based on these patterns, two candidate ARIMA specifications are selected: (2,1,0)(2,1,0)[12] and (2,1,0)(0,1,1)[12], alongside an automatically selected ARIMA model.


## Model comparison using information criteria

### ETS model comparison

```{r}

# Fitting ETS models on raw (untransformed) data
ets_models <- retail_train |>
  model(
    ETS_AAdA = ETS(turnover ~ error("A") + trend("Ad") + season("A")),
    ETS_MAdA = ETS(turnover ~ error("M") + trend("Ad") + season("A")),
    ETS_MAdM = ETS(turnover ~ error("M") + trend("Ad") + season("M")),
    ETS_auto = ETS(turnover) 
  )

# Checking which model the Auto ETS selected
ets_models |> 
  select(ETS_auto) |> 
  report()

```


```{r}
#| label: tbl-table5

# Compare AIC values and model details
glance(ets_models) |> 
  # select(-c(state, industry)) |> 
  arrange(AIC)

```

The candidate ETS models are fitted to the training data and compared using the Akaike Information Criterion (AIC), with results summarized in @tbl-table5. The automatically selected ETS model, ETS(M,A,M), achieves the lowest AIC, indicating the best in-sample fit among the specifications considered.

However, the damped-trend models ETS(M,Ad,A) and ETS(M,Ad,M) perform comparably in terms of AIC, with only marginally higher values. Given their damped trend structure, these models remain plausible alternatives, particularly if long-run growth is expected to slow.

Note: ETS models are fitted to the original turnover series, as exponential smoothing methods natively accommodate trend and seasonality without requiring prior differencing or transformation.

### ARIMA model comparison

```{r}
#| label: tbl-table6

# Modelling the selected models and the auto selected ARIMA model
# Using stepwise and approximation = false to allow the function
# to search deeper and harder for the best fitting model

arima_models <- retail_train |>
  model(
    model1 = ARIMA(box_cox(turnover, 0) ~ pdq(2, 1, 0) + PDQ(2, 1, 0)),
    model2 = ARIMA(box_cox(turnover, 0) ~ pdq(2, 1, 0) + PDQ(0, 1, 1)),
    auto = ARIMA(box_cox(turnover, 0), stepwise = FALSE, approximation = FALSE)
  )

# Clean printing the models and auto selected model.

arima_models |> 
  # select(-state, -industry) |> 
  pivot_longer(everything(),
  names_to = "Model name",
  values_to = "Orders"
)

```

```{r}
#| label: tbl-table7

# Viewing model performance statistics, arranged by AIC

glance(arima_models) |> 
  arrange(AIC) |> 
  select(.model:BIC)

```


A similar comparison is conducted for the ARIMA candidates. The automatically selected ARIMA model matches the manually specified (2,1,0)(0,1,1)[12] model, as shown in @tbl-table6. Both specifications achieve the lowest AIC values in @tbl-table7, indicating strong in-sample performance relative to the alternative candidate.

## Test-set evaluation and final model selection

```{r}

# Generate forecasts for the next 24 months
forecasts_ets <- ets_models |> 
  forecast(new_data = retail_test)

forecasts_arima <- arima_models |> 
  forecast(new_data = retail_test)

# Evaluate forecast accuracy for ETS models
accuracy_ets <- fabletools::accuracy(forecasts_ets, retail_test) |> 
  # select(-c(state, industry)) |> 
  arrange(RMSE)

# Evaluate forecast accuracy for ARIMA models
accuracy_arima <- fabletools::accuracy(forecasts_arima, retail_test) |> 
  # select(-c(state, industry)) |> 
  arrange(RMSE)

```

```{r}
#| label: tbl-table8

accuracy_ets
```

```{r}
#| label: tbl-table9

accuracy_arima

```

To assess out-of-sample performance, all shortlisted ETS and ARIMA models are evaluated on a 24-month test set. Forecast accuracy metrics for ETS and ARIMA models are reported in @tbl-table8 and @tbl-table9, respectively.

For the ARIMA models, the (2,1,0)(0,1,1)[12] specification achieves both the lowest AIC and the lowest test-set RMSE, and is also selected automatically by the ARIMA procedure. This consistency provides strong support for its selection as the preferred ARIMA model.

For the ETS models, the automatically selected ETS(M,A,M) model achieves the lowest AIC but performs less well on the test set. In contrast, ETS(M,Ad,A) delivers the lowest test-set RMSE among ETS candidates while maintaining a competitive AIC value. Given its superior out-of-sample performance and damped trend structure, ETS(M,Ad,A) is selected as the preferred ETS model.

These two models are carried forward for detailed diagnostics and forecasting in the next section.


# Evaluation

